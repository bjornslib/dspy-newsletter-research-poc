{"id":"dspy-0s9","title":"DSPy Classification, Scoring, and Summarization Pipeline","description":"Implement DSPy-based classification (region, topics, country), relevance scoring with reasoning, and 2-3 sentence summarization stages over relevant articles.","acceptance_criteria":"- ArticleClassifier with TypedPredictor working\n- RelevanceScorer with ChainOfThought working\n- Summarizer with Predict working\n- Pipeline chains correctly: classify → score → summarize\n- ProcessedArticle JSONL output valid","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:56:33.087793+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:33.087793+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-0s9","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:49.376892+11:00","created_by":"theb"},{"issue_id":"dspy-0s9","depends_on_id":"dspy-2yy","type":"blocks","created_at":"2026-01-12T16:59:07.273912+11:00","created_by":"theb"}]}
{"id":"dspy-13p","title":"Weaviate Storage Integration for Processed Articles","description":"Store processed articles into Weaviate NewsletterArticles collection with embeddings and metadata, maintaining JSONL processing log.","acceptance_criteria":"- Articles inserted with correct properties\n- Embeddings generated via text2vec-openai\n- Batch API used for efficiency\n- Processing log entries for stored_weaviate\n- Articles queryable via hybrid search","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:56:38.903903+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:38.903903+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-13p","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:55.287408+11:00","created_by":"theb"},{"issue_id":"dspy-13p","depends_on_id":"dspy-0s9","type":"blocks","created_at":"2026-01-12T16:59:13.230818+11:00","created_by":"theb"}]}
{"id":"dspy-2k6","title":"DSPy Newsletter Research Tool PoC","description":"Automated newsletter research system using DSPy, retrieve-dspy QUIPLER, Weaviate, and Cohere reranking. Transforms manual 20+ hours/week research into an intelligent agent-based query system achieving 70%+ recall.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-12T16:55:01.011043+11:00","created_by":"theb","updated_at":"2026-01-12T16:55:01.011043+11:00","labels":["dspy_poc"],"dependencies":[{"issue_id":"dspy-2k6","depends_on_id":"dspy-u3v","type":"blocks","created_at":"2026-01-12T17:06:41.784569+11:00","created_by":"theb"}]}
{"id":"dspy-2yy","title":"DSPy Tiny LM Relevance Pre-Filter (gpt-4o-mini)","description":"Implement DSPy-based tiny LM semantic relevance filter using gpt-4o-mini to reduce ~400 deduped articles to ~150-200 candidates per day.","acceptance_criteria":"- RelevancePreFilter signature implemented\n- dspy.Predict module working with gpt-4o-mini\n- Relevant articles filtered to work_queue/relevant/\n- Unrelated articles filtered out\n- Processing time \u003c5 minutes for 500 articles","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:56:04.316151+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:04.316151+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-2yy","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:43.553021+11:00","created_by":"theb"},{"issue_id":"dspy-2yy","depends_on_id":"dspy-50z","type":"blocks","created_at":"2026-01-12T16:59:01.458604+11:00","created_by":"theb"}]}
{"id":"dspy-4aa","title":"Data Labeling, DSPy Optimization (BootstrapFewShot), and Monitoring","description":"Collect labeled examples for key DSPy signatures, run BootstrapFewShot optimization to reach ≥70% classification accuracy/recall, and implement monitoring dashboards.","acceptance_criteria":"- 150+ labeled examples collected\n- BootstrapFewShot optimization complete\n- Classification accuracy ≥70%\n- Recall ≥70% vs manual process\n- Monitoring metrics dashboard working","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-12T16:56:56.391098+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:56.391098+11:00","labels":["dspy_poc","phase-3"],"dependencies":[{"issue_id":"dspy-4aa","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:58:12.961592+11:00","created_by":"theb"},{"issue_id":"dspy-4aa","depends_on_id":"dspy-v72","type":"blocks","created_at":"2026-01-12T16:59:31.205822+11:00","created_by":"theb"}]}
{"id":"dspy-4tp","title":"Core Data Models, Taxonomy, and Processing Log Schema","description":"Define Python Pydantic models for articles, taxonomy (regions, topics), and JSONL processing audit log for consistent structured data throughout the pipeline.","acceptance_criteria":"- RawArticle and ProcessedArticle models validate correctly\n- Invalid region/topic codes raise validation errors\n- ProcessingLogEntry serialization works\n- Audit logging appends to JSONL correctly","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:55:46.518712+11:00","created_by":"theb","updated_at":"2026-01-12T16:55:46.518712+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-4tp","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:25.880149+11:00","created_by":"theb"},{"issue_id":"dspy-4tp","depends_on_id":"dspy-fx7","type":"blocks","created_at":"2026-01-12T16:58:37.771565+11:00","created_by":"theb"}]}
{"id":"dspy-50z","title":"Deduplication Module (Hash + Fuzzy Matching)","description":"Implement deduplication over raw article queue using exact hash and fuzzy content similarity to reduce to ~400 unique daily articles.","acceptance_criteria":"- Identical articles result in only one output\n- Fuzzy duplicates flagged (\u003e90% similarity)\n- Distinct articles preserved\n- Deterministic output on re-run\n- Performance \u003c5 seconds for 1000 articles","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:55:58.36021+11:00","created_by":"theb","updated_at":"2026-01-12T16:55:58.36021+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-50z","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:37.702931+11:00","created_by":"theb"},{"issue_id":"dspy-50z","depends_on_id":"dspy-7eh","type":"blocks","created_at":"2026-01-12T16:58:55.575931+11:00","created_by":"theb"}]}
{"id":"dspy-5xm","title":"AT-E2E: Query Agent E2E Validation","description":"Write E2E tests validating the QUIPLER query agent against real Weaviate data. Tests should exercise query expansion, Cohere reranking, and ReAct synthesis. Include complex multi-hop query scenarios.","design":"Create tests/integration/test_query_e2e.py. Test scenarios: (1) Simple query 'Latest FCRA updates', (2) Standard query 'Regulation changes in APAC', (3) Complex multi-hop query 'How has GDPR enforcement evolved post-Brexit...'. Verify: answer quality, source citations, latency targets (\u003c3s simple, \u003c10s complex).","acceptance_criteria":"All 3 query complexity tiers tested and passing. Response quality validated. Latency within targets. Sources correctly cited.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T17:07:18.729809+11:00","created_by":"theb","updated_at":"2026-01-12T17:07:18.729809+11:00","labels":["acceptance-tests","dspy_poc","e2e-tests"],"dependencies":[{"issue_id":"dspy-5xm","depends_on_id":"dspy-u3v","type":"parent-child","created_at":"2026-01-12T17:07:43.685349+11:00","created_by":"theb"},{"issue_id":"dspy-5xm","depends_on_id":"dspy-v72","type":"blocks","created_at":"2026-01-12T17:08:09.725558+11:00","created_by":"theb"}]}
{"id":"dspy-7eh","title":"RSS Ingestion and Raw Article Queue","description":"Implement daily RSS ingestion job for 20+ tier-1 feeds, parsing entries into RawArticle objects and storing them in raw queue for downstream processing.","acceptance_criteria":"- 20 RSS feeds ingesting successfully\n- JSONL file created in raw_queue/\n- Each line parses to valid RawArticle\n- Idempotency: duplicates prevented on re-run\n- Processing log entries created","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:55:52.400253+11:00","created_by":"theb","updated_at":"2026-01-12T16:55:52.400253+11:00","labels":["dspy_poc","phase-1b-ingest"],"dependencies":[{"issue_id":"dspy-7eh","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:31.782046+11:00","created_by":"theb"},{"issue_id":"dspy-7eh","depends_on_id":"dspy-fx7","type":"blocks","created_at":"2026-01-12T16:58:43.537794+11:00","created_by":"theb"},{"issue_id":"dspy-7eh","depends_on_id":"dspy-4tp","type":"blocks","created_at":"2026-01-12T16:58:49.652696+11:00","created_by":"theb"}]}
{"id":"dspy-8nc","title":"AT-Integration: Pipeline Integration Tests","description":"Write integration tests validating the full processing pipeline: Ingestion → Deduplication → TinyLM Filter → Classification/Scoring → Weaviate Storage. Tests should use real Weaviate (Docker) with test data, not mocks.","design":"Create tests/integration/test_pipeline_e2e.py. Test full article flow from RSS feed mock through Weaviate storage. Verify: (1) Article ingested correctly, (2) Duplicates rejected, (3) Irrelevant articles filtered, (4) Classification/scoring applied, (5) Stored in Weaviate with correct embeddings.","acceptance_criteria":"End-to-end pipeline test passing. Sample articles flow through all stages correctly. Weaviate contains expected data with proper metadata.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T17:07:13.071981+11:00","created_by":"theb","updated_at":"2026-01-12T17:07:13.071981+11:00","labels":["acceptance-tests","dspy_poc","integration-tests"],"dependencies":[{"issue_id":"dspy-8nc","depends_on_id":"dspy-u3v","type":"parent-child","created_at":"2026-01-12T17:07:38.128639+11:00","created_by":"theb"},{"issue_id":"dspy-8nc","depends_on_id":"dspy-13p","type":"blocks","created_at":"2026-01-12T17:08:04.166713+11:00","created_by":"theb"}]}
{"id":"dspy-bot","title":"CLI Interface (Click + Rich) and Batch Orchestration","description":"Provide user-friendly CLI for querying, listing candidates, viewing statistics, and wire cron-based orchestration for daily batch pipeline.","acceptance_criteria":"- CLI query command working with filters\n- CLI list command showing candidates\n- CLI stats command showing metrics\n- run_daily_batch.py orchestrates full pipeline\n- Rich formatting for output","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-12T16:56:50.519347+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:50.519347+11:00","labels":["dspy_poc","phase-1b-query"],"dependencies":[{"issue_id":"dspy-bot","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:58:07.044551+11:00","created_by":"theb"},{"issue_id":"dspy-bot","depends_on_id":"dspy-v72","type":"blocks","created_at":"2026-01-12T16:59:25.121526+11:00","created_by":"theb"}]}
{"id":"dspy-fx7","title":"Project \u0026 Infrastructure Setup (Python, DSPy, Weaviate Docker)","description":"Initialize Python project, configure dependencies, environment variables, and bring up local Weaviate instance via Docker Compose with specified schema.","acceptance_criteria":"- Docker compose starts Weaviate successfully\n- Python connects to Weaviate\n- DSPy configured with OpenAI + Cohere\n- Collection schema deployed\n- Health check script passes","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:55:40.616716+11:00","created_by":"theb","updated_at":"2026-01-12T16:55:40.616716+11:00","labels":["dspy_poc","phase-1a"],"dependencies":[{"issue_id":"dspy-fx7","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:57:20.045622+11:00","created_by":"theb"}]}
{"id":"dspy-u3v","title":"AT-DSPy Newsletter Research Tool (Acceptance Tests)","description":"Acceptance Test epic for DSPy Newsletter Research Tool PoC. Contains all test tasks following TDD red-green-refactor methodology. Must be completed and validated before functional epic can be closed.","acceptance_criteria":"All unit tests passing with ≥80% coverage. Integration tests validating end-to-end pipeline. Query E2E tests confirming QUIPLER retrieval works.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-12T17:06:29.831192+11:00","created_by":"theb","updated_at":"2026-01-12T17:06:29.831192+11:00","labels":["acceptance-tests","dspy_poc"]}
{"id":"dspy-v72","title":"QUIPLER-based Retrieval and ReAct Query Agent","description":"Implement QUIPLER-based retrieval layer over Weaviate and DSPy ReAct query agent with tools for filtering and article detail access.","acceptance_criteria":"- QUIPLER retrieval working with Cohere reranking\n- ReAct agent with tools (filter_by_date, filter_by_region, filter_by_topic, get_article_details)\n- Query returns answer, confidence, cited_articles\n- Simple query latency \u003c5 seconds\n- Complex query latency \u003c10 seconds","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-12T16:56:44.720696+11:00","created_by":"theb","updated_at":"2026-01-12T16:56:44.720696+11:00","labels":["dspy_poc","phase-1b-query"],"dependencies":[{"issue_id":"dspy-v72","depends_on_id":"dspy-2k6","type":"parent-child","created_at":"2026-01-12T16:58:01.141445+11:00","created_by":"theb"},{"issue_id":"dspy-v72","depends_on_id":"dspy-13p","type":"blocks","created_at":"2026-01-12T16:59:19.280371+11:00","created_by":"theb"}]}
{"id":"dspy-xgl","title":"AT-Unit: DSPy Module Unit Tests (Red-Green-Refactor)","description":"Write and validate unit tests for all DSPy modules following TDD red-green-refactor methodology. Each module gets its own test file mapped to its Beads task. Tests must be written BEFORE implementation (RED phase), then implementation makes them pass (GREEN phase), then refactor with ≥80% coverage.","design":"Test files: test_infrastructure.py (dspy-fx7), test_models.py (dspy-4tp), test_ingestion.py (dspy-7eh), test_deduplication.py (dspy-50z), test_prefilter.py (dspy-2yy), test_classification.py (dspy-0s9), test_storage.py (dspy-13p), test_query_agent.py (dspy-v72), test_cli.py (dspy-bot), test_optimization.py (dspy-4aa). Use pytest with mocking for LLM calls. Follow patterns in TDD_TESTING_STRATEGY.md.","acceptance_criteria":"All 10 test modules created and passing. Each module has ≥80% coverage. Validation-agent confirms RED→GREEN→REFACTOR for each module.","status":"in_progress","priority":1,"issue_type":"task","created_at":"2026-01-12T17:07:07.451971+11:00","created_by":"theb","updated_at":"2026-01-12T17:09:33.619059+11:00","labels":["acceptance-tests","dspy_poc","unit-tests"],"dependencies":[{"issue_id":"dspy-xgl","depends_on_id":"dspy-u3v","type":"parent-child","created_at":"2026-01-12T17:07:32.577507+11:00","created_by":"theb"}]}
